{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9094aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/student/.local/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: networkx in /home/student/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/student/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/student/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/student/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/student/.local/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/student/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/student/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: fsspec in /home/student/.local/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/student/.local/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/student/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/student/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/student/.local/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/student/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/student/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/student/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/student/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ec5e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in /home/student/.local/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: torch==2.2.1 in /home/student/.local/lib/python3.10/site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch==2.2.1->torchvision) (1.9)\n",
      "Requirement already satisfied: fsspec in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.2.1->torchvision) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (4.9.0)\n",
      "Requirement already satisfied: networkx in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/student/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/student/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision) (12.3.101)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a9cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b7e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b53401",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 3\n",
    "batch_size = 4\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c200744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d4ce24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = iter(test_loader)\n",
    "example_data, example_targets = examples.__next__()\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dcce5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential( nn.Conv2d(1,64,kernel_size = 3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2), stride = 2),\n",
    "                                 nn.Conv2d(64,128,kernel_size = 3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2), stride = 2),\n",
    "                                 nn.Conv2d(128,64,kernel_size = 3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2), stride = 2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(\n",
    "                                nn.Linear(64,20,bias = True),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(20,10,bias = True)\n",
    "                                )\n",
    "    def forward(self, x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86af913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f7ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065f0dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(cp, filename):\n",
    "    torch.save(cp, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d336714a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.0010\n",
      "Epoch [2/3], Loss: 0.0000\n",
      "Epoch [3/3], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    if(epoch == 2):\n",
    "        checkpoint = {'model': model.state_dict(),\n",
    "                     'optim': optimizer.state_dict(),\n",
    "                      'loss': loss,\n",
    "                      'epoch_num': epoch\n",
    "                     }\n",
    "        save_checkpoint(checkpoint, 'my_saved_check.pt')\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader): \n",
    "        \n",
    "        # origin shape: [4, 1, 28, 28]\n",
    "        # resized: [4, 784]\n",
    "        #images = images.reshape(-1, 28*28).to(device)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01bb4c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_check(loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in loader:\n",
    "            #images = images.reshape(-1, 28*28).to(device)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4887c665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\n",
      "\n",
      "Accuracy of the network on the 10000 test images: 99.36333333333333 %\n",
      "Testing accuracy:\n",
      "\n",
      "Accuracy of the network on the 10000 test images: 98.51 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy:\\n\") \n",
    "acc_check(train_loader)\n",
    "print(\"Testing accuracy:\\n\") \n",
    "acc_check(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0cb9dd",
   "metadata": {},
   "source": [
    "# Part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c089511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97d27f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genGaussian(tindx):\n",
    "    return torch.normal(tindx[0], tindx[1], (1,28,28))\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        classes = {0: (0.5, 2), 1: (1, 2.5)}\n",
    "        self.y = [torch.round(torch.rand(1))[0].long() for i in range(n)]\n",
    "        self.x = [genGaussian(classes[self.y[i].item()]) for i in range(n)]\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6bdb92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = myDataset(20) #generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8825a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf542dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[[[ 0.7447,  3.0993,  1.7513,  ...,  0.5454, -3.0765,  3.8262],\n",
      "          [-2.9133,  0.1206, -2.4121,  ...,  2.1893, -1.5133,  0.5616],\n",
      "          [ 0.4317,  0.7325,  2.0999,  ...,  3.8638,  0.6724, -0.6132],\n",
      "          ...,\n",
      "          [ 3.3274, -2.3565,  2.6706,  ..., -0.9579,  0.3819, -1.2408],\n",
      "          [ 0.7610, -3.1219,  0.6756,  ..., -1.8285, -1.2630, -1.3972],\n",
      "          [-0.1652,  0.9302, -1.0886,  ...,  0.9017,  3.2513,  1.4431]]],\n",
      "\n",
      "\n",
      "        [[[-3.1905,  2.0222, -0.3588,  ...,  7.2604,  1.8907, -3.4143],\n",
      "          [ 5.7692,  2.3903,  1.8191,  ...,  3.8136,  5.5115,  7.4887],\n",
      "          [ 3.5587,  2.3749,  2.0306,  ..., -0.4546,  1.3477, -2.4495],\n",
      "          ...,\n",
      "          [ 1.8027,  2.8814, -0.3936,  ...,  1.5548, -0.7242, -2.4506],\n",
      "          [ 1.2066,  0.0815, -0.2797,  ..., -4.1345, -2.4537, -0.7404],\n",
      "          [-1.4129, -0.6807,  2.9352,  ...,  1.2528,  0.7097, -2.4006]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7157,  1.3162,  5.3412,  ..., -3.0697,  1.2970,  1.5401],\n",
      "          [ 2.6654, -0.0898,  1.9086,  ..., -1.6938, -1.4453,  0.1281],\n",
      "          [ 4.8606,  0.1070,  1.6441,  ..., -1.8325,  5.1663,  2.0182],\n",
      "          ...,\n",
      "          [-2.4090,  0.3951, -0.8517,  ...,  1.2592, -1.3903,  2.2640],\n",
      "          [ 5.2470,  1.4385,  2.2044,  ...,  2.4182,  3.2539,  2.5866],\n",
      "          [-1.8395,  4.3456,  1.8930,  ...,  3.3493, -0.2148, -4.7770]]],\n",
      "\n",
      "\n",
      "        [[[-0.1695,  2.5729, -0.7453,  ...,  0.8221,  0.2823,  0.4043],\n",
      "          [ 0.9507,  1.3493,  3.5217,  ..., -0.1166,  0.9802,  4.5898],\n",
      "          [-0.9550, -0.3962, -2.0974,  ...,  1.4009,  0.2002,  2.5592],\n",
      "          ...,\n",
      "          [-2.4689,  0.1763,  0.1044,  ...,  1.8405,  1.5812,  2.1396],\n",
      "          [ 1.1971,  2.5572,  2.0953,  ...,  0.3251,  1.5024,  1.6964],\n",
      "          [ 0.4780,  0.9228,  1.8316,  ...,  1.3193, -1.5473,  1.7003]]]]), tensor([0, 1, 1, 0])]\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(dataloader):\n",
    "    print(i, d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f90114a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "08ede114",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('my_saved_check.pt')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optim'])\n",
    "epoch = checkpoint['epoch_num']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5fbb13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#editing model parameters\n",
    "model.classification_head = nn.Sequential(\n",
    "                                nn.Linear(64,20,bias = True),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(20,2,bias = True)\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "62d6fa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classification_head): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d46b3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "60f2f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c61ab653",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_steps = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a67b77c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.9644\n",
      "Epoch [2/3], Loss: 0.3182\n",
      "Epoch [3/3], Loss: 0.0609\n"
     ]
    }
   ],
   "source": [
    "#training the model again:\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (images, labels) in enumerate(dataloader): \n",
    "        \n",
    "        # origin shape: [4, 1, 28, 28]\n",
    "        # resized: [4, 784]\n",
    "        #images = images.reshape(-1, 28*28).to(device)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "88fffc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking accuracy of new model:\n",
    "def acc_check(loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in loader:\n",
    "            #images = images.reshape(-1, 28*28).to(device)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ed068c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 95.0 %\n"
     ]
    }
   ],
   "source": [
    "acc_check(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78751e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

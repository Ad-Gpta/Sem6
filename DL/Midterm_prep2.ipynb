{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch NN:\n",
    "\n",
    "Source: https://www.youtube.com/watch?v=Jy4wM2X21u0&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure:\n",
    "\n",
    "imports\n",
    "\n",
    "create fully connected nn\n",
    "\n",
    "set device\n",
    "\n",
    "hyperparameters\n",
    "\n",
    "load data\n",
    "\n",
    "Initialize network\n",
    "\n",
    "loss and optimizer\n",
    "\n",
    "train network\n",
    "\n",
    "check accuracy - on both train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "import torch.optim as optim\n",
    "#optimizer; helps reduce loss fcn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "#F contains activation functions like RelU - but they are also contained\n",
    "#in the nn package. can use either\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# easier dataset management - gives us minibatches to train on\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "#will be used to import standard datasets like MNIST\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "#essentially has tranformations we can perform on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "#creating the Fully connected NN\n",
    "class NN(nn.Module): #inherit the Module\n",
    "    def __init__(self, input_size, num_classes): \n",
    "        super().__init__() #run constructor of nn.Module - inherit\n",
    "        \n",
    "        #layers we want to include in our NN:\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        #MNIST Dataset: 28x28 = 784 images => 784 nodes\n",
    "        #or setting number of hidden nodes to 50\n",
    "        \n",
    "        \n",
    "        #layer 2-> goes from 50 (hidden layer neurons) to number of classes\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    \n",
    "    def forward(self, x): #forward runs on input x\n",
    "        z = self.fc1(x)\n",
    "        y_p = F.relu(z) #non-linearization\n",
    "        y_p = self.fc2(y_p) #Reaches output layer\n",
    "        return y_p\n",
    "    \n",
    "#testing if model works for some random inputs:\n",
    "\n",
    "model = NN(784, 10)\n",
    "#784 - number of images in MNIST\n",
    "#10 - number of digits\n",
    "x = torch.randn(64, 784)\n",
    "#64 - number of examples we are going to run simultaneously\n",
    "#number of images essentially\n",
    "\n",
    "print(model(x).shape) \n",
    "#print the shape of the output - we want 64x10\n",
    "# probability of number/picture i belonging to class j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set device:\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set hyperparameters:\n",
    "input_size = 784\n",
    "number_of_classes = 10\n",
    "l_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "\n",
    "transformer = transforms.ToTensor() \n",
    "#transforms data to a tensor\n",
    "\n",
    "trainset = datasets.MNIST(root='datasets/', train=True,\\\n",
    "                          transform = transformer, download = True)\n",
    "#root - where the dataset should be saved; \n",
    "#here, creates and saves in a folder called datasets\n",
    "#download = True -> will download dataset if we don't have it\n",
    "\n",
    "trainloader = DataLoader(dataset = trainset, batch_size = batch_size,\\\n",
    "                         shuffle = True)\n",
    "#shuffle -> shuffles images in the batches between epochs\n",
    "#=> every epoch, the images in a batch changes\n",
    "\n",
    "testset = datasets.MNIST(root='datasets/', train=False,\\\n",
    "                          transform = transformer, download = True)\n",
    "testloader = DataLoader(dataset = testset, batch_size = batch_size,\\\n",
    "                         shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#my own code: \n",
    "#taking a look at the data\n",
    "\n",
    "examples = iter(testloader)\n",
    "e_data, e_label = examples.__next__() #gets next batch of data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(e_data[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the network\n",
    "model = NN(input_size = input_size, num_classes = number_of_classes)\\\n",
    ".to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "#loss function for logistic regression - predicting which of 10 classes\n",
    "#given image belongs to\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = l_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the network:\n",
    "\n",
    "#one epoch - model has seen all images in trainset\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, targets) in enumerate(trainloader): \n",
    "        #ip and op/correct label - data, targets\n",
    "        #enumerate - gives us batch index of data too\n",
    "        \n",
    "        #checking if data is in correct shape:\n",
    "        \"\"\"original shape of images : [batch_size, 1, 28, 28]\n",
    "        can find this out by printing:\n",
    "        print(data.shape) - prints shape of data for each batch\n",
    "        need it to be of shape [batch_size, 784]\"\"\"\n",
    "        \n",
    "        data = data.reshape(data.shape[0], -1) \n",
    "        #-1 flattens everything else to a single dimension\n",
    "        # print(data.shape) - torch.Size([64, 784]) for each batch\n",
    "        \n",
    "        #first, transfer the data and labels to device\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        #forward - inputs go through all layers in the model - 1 pass\n",
    "        scores = model(data)\n",
    "        #data is not in size expected for fc1\n",
    "        #fc1 - 784 ip nodes \n",
    "        #data - 1 batch of 64 instances/images each with 28x28 image size\n",
    "        \n",
    "        #after performing forward opr - or one pass of data\n",
    "        #calculate the loss\n",
    "        loss = criterion(scores, targets) #pred, actual\n",
    "        \n",
    "        #set all gradients to zero \n",
    "        #to properly calc gradients during backward pass\n",
    "        optimizer.zero_grad()\n",
    "        #makes sure it is not storing backprop values from prev batch\n",
    "        \n",
    "        #backward prop\n",
    "        #go backward - back to start for the next batch\n",
    "        #also calculate all gradients along the way\n",
    "        loss.backward()\n",
    "        \n",
    "        #gradient descent or adam step - performs a single optim step\n",
    "        #updates the parameters of model based on gradients and backward pass\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i, j in testloader:\n",
    "    print(i.shape, j.shape)\n",
    "    i = i.reshape(i.shape[0], -1)\n",
    "    print(i.shape, j.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy = 55794/60000 = 0.9298999905586243 = 92.98999786376953%\n",
      " accuracy = 9316/10000 = 0.9315999746322632 = 93.15999603271484%\n"
     ]
    }
   ],
   "source": [
    "#evaluate the network:\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    model.eval() #puts the model in eval mode - behaves a bit diffirently\n",
    "    \n",
    "    with torch.no_grad(): #gradients dont need to be computed during testing\n",
    "        for x, y in loader: #iterates through every batch\n",
    "            #x = x.to(device)\n",
    "            #y = y.to(device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            \n",
    "            scores = model(x)\n",
    "            #shape of scores will be 64x10 - 64 inputs 10 classes\n",
    "            #10 - contains prob of img being of that class\n",
    "            \n",
    "            #want to know which of the 10 has maximum prob\n",
    "            \n",
    "            #print(scores.max(1)) - torch.return_types.max(values=tensor([7.3685]),indices=tensor([7]))\n",
    "            \n",
    "            _, predictions = scores.max(1) #computes max along dim=1\n",
    "            #this gives us the value, index but we're not interested \n",
    "            #in the value, only the index\n",
    "            \n",
    "            \n",
    "            num_correct += (predictions == y).sum()\n",
    "            #for every x, y (every batch), adds total number of 'true' preds\n",
    "            \n",
    "            num_samples += predictions.size(0) #adds batch size every itr\n",
    "        \n",
    "        #after 1 epoch - 1 pass through all batches:\n",
    "        acc = num_correct/num_samples\n",
    "        print(f\" accuracy = {num_correct}/{num_samples} = {acc} = {acc*100}%\")\n",
    "        \n",
    "        #return model to train if necessary:\n",
    "        model.train()\n",
    "        #done when you're checking accuracy of model in the \n",
    "        #middle of training\n",
    "        \n",
    "        return acc\n",
    "        \n",
    "acc1 = check_accuracy(trainset, model)\n",
    "acc2 = check_accuracy(testset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "dim 0 -> rows;\n",
    "dim 1 -> cols;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch CNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs work a lot better on image datasets than NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels = 1, num_classes= 10):\n",
    "        super().__init__()\n",
    "        #define all the layers to be used in the network\n",
    "        \n",
    "        #Feature extractor layers:\n",
    "        \n",
    "        #creating convolutional layer:\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, \\\n",
    "                             kernel_size= 3, stride = 1)\n",
    "        #in_channels = 1 -> greyscale img\n",
    "        #out_channels - number of channels in output of this layer\n",
    "                # set to an arbitrary number - 8\n",
    "            \n",
    "        #can use ReLU here\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        #makes a 28x28 image into 14x14 and 14x14 into 7x7 image\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, \\\n",
    "                             kernel_size= 3, stride = 1)\n",
    "        \n",
    "        #classification head:\n",
    "        self.fc1 = nn.Linear(16*5*5, num_classes)\n",
    "        #input_size = 16 channels * 7x7 image \n",
    "        #shape of x after feature extraction:  torch.Size([64, 16, 5, 5])\n",
    "        #so changing 7*7 into 5*5\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #feature extraction:\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        print(\"shape of x after feature extraction: \", x.shape)\n",
    "        \n",
    "        #classification:\n",
    "        x = x.reshape(x.shape[0], -1) #number of batches, pixels\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "shape of x after feature extraction:  torch.Size([64, 16, 5, 5])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "x_test = torch.randn(64, 1, 28, 28) #inital size of each batch in MNIST\n",
    "# we plan on setting batch size 64\n",
    "print(x_test.shape)\n",
    "print(model(x_test).shape)\n",
    "\n",
    "#got the desired shape of 64 x 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can now train the network:\n",
    "#and check accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(784, 10) #just setting model to the NN example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user defined function to save checkpoint\n",
    "def save_checkpoint(state, filename='my_checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while training, can enter this code:\n",
    "\n",
    "checkpoint = {'model': model.state_dict(), 'optimizer' : optimizer.state_dict()}\n",
    "#saves current vallues of all params - or the current state dict\n",
    "\n",
    "save_checkpoint(checkpoint)\n",
    "#user defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "OrderedDict([('fc1.weight', tensor([[-0.0079, -0.0074, -0.0336,  ...,  0.0105,  0.0202, -0.0100],\n",
      "        [-0.0111,  0.0177, -0.0288,  ..., -0.0152,  0.0020,  0.0244],\n",
      "        [-0.0195, -0.0243,  0.0164,  ...,  0.0121, -0.0251, -0.0141],\n",
      "        ...,\n",
      "        [ 0.0031,  0.0082, -0.0324,  ...,  0.0009, -0.0177,  0.0300],\n",
      "        [-0.0071,  0.0199,  0.0345,  ...,  0.0009, -0.0020,  0.0282],\n",
      "        [-0.0237, -0.0203, -0.0084,  ..., -0.0134, -0.0203, -0.0165]])), ('fc1.bias', tensor([-0.0114,  0.0086, -0.0136,  0.0278,  0.0050,  0.0327, -0.0219, -0.0289,\n",
      "        -0.0116, -0.0031,  0.0226,  0.0145,  0.0246, -0.0317, -0.0034,  0.0319,\n",
      "         0.0240,  0.0275, -0.0158, -0.0232,  0.0244, -0.0209, -0.0223, -0.0040,\n",
      "         0.0186,  0.0243,  0.0095, -0.0096, -0.0036,  0.0271, -0.0093, -0.0129,\n",
      "        -0.0218, -0.0230,  0.0040,  0.0002, -0.0193,  0.0110,  0.0101, -0.0102,\n",
      "        -0.0031,  0.0303, -0.0290, -0.0333, -0.0209, -0.0222, -0.0243, -0.0158,\n",
      "         0.0114, -0.0195])), ('fc2.weight', tensor([[-8.5111e-02, -2.6967e-02,  4.0721e-02,  1.0242e-01,  5.3110e-03,\n",
      "         -9.9353e-02,  2.7366e-02, -1.0253e-01,  1.6030e-02,  1.4060e-01,\n",
      "         -1.3935e-01,  2.1673e-02,  4.3561e-03,  1.2506e-01,  1.0318e-01,\n",
      "         -5.5172e-02, -1.0800e-01,  3.5290e-02,  4.9588e-02, -5.8385e-02,\n",
      "         -1.6713e-02,  1.2471e-02, -1.1122e-02,  1.4080e-01,  1.1702e-01,\n",
      "         -9.9656e-02,  7.7203e-02,  5.8800e-02, -9.2793e-02, -1.3136e-01,\n",
      "          9.0227e-02,  1.0370e-01, -1.0250e-01, -4.8167e-02,  1.1677e-01,\n",
      "          9.2075e-02, -1.2475e-01, -9.4863e-02, -4.1576e-02,  1.4802e-02,\n",
      "          1.0047e-01, -9.9670e-02,  5.1891e-02, -9.7600e-02, -1.1597e-01,\n",
      "         -5.2097e-02,  1.2943e-01, -1.5634e-02,  7.9725e-02, -9.1235e-02],\n",
      "        [ 5.6745e-02,  5.8979e-02, -1.2789e-01, -1.3993e-01,  5.2843e-02,\n",
      "         -2.6888e-02,  3.5907e-02,  5.1491e-02,  1.0293e-01,  1.0989e-01,\n",
      "         -1.2013e-02, -1.1607e-01,  5.4467e-03, -7.7595e-02,  9.2949e-02,\n",
      "         -7.8174e-02,  2.9728e-02, -5.3472e-02, -1.3664e-01, -2.1406e-02,\n",
      "          3.8913e-02,  7.6561e-02, -5.5879e-02, -4.0517e-03,  1.0664e-01,\n",
      "         -5.4077e-02,  8.7383e-02,  5.0574e-02, -3.6304e-02,  4.7840e-02,\n",
      "         -1.7673e-02,  4.7790e-04, -6.3647e-02, -4.4322e-02, -1.0065e-01,\n",
      "          1.3064e-01, -2.7647e-02, -1.1729e-01, -1.2629e-01,  4.1562e-02,\n",
      "         -2.0325e-02, -8.7435e-02, -8.4438e-02,  8.3489e-02,  7.5674e-02,\n",
      "          1.1316e-01, -1.1180e-01,  7.7998e-02,  1.4174e-02, -8.4181e-02],\n",
      "        [ 1.2063e-01,  5.3821e-03,  1.0476e-01,  9.3792e-02, -1.1917e-01,\n",
      "         -1.1197e-01, -9.8480e-02, -4.7759e-02, -1.6945e-02, -1.6225e-02,\n",
      "         -5.9874e-02,  3.2621e-02, -1.2362e-01,  9.8217e-02,  1.0539e-01,\n",
      "         -3.8352e-02,  1.0162e-01, -6.5837e-02,  2.5901e-02, -1.3159e-01,\n",
      "          7.1269e-02,  1.3329e-01, -1.7324e-02,  8.0095e-02, -8.4775e-02,\n",
      "         -1.8304e-02, -4.0505e-02, -7.9294e-02,  8.1017e-02, -3.3909e-02,\n",
      "         -8.7001e-02, -7.9297e-02, -1.0501e-02,  9.2333e-02, -1.1130e-01,\n",
      "          9.0194e-02,  1.9277e-02, -5.2298e-02, -6.5950e-02,  6.8567e-02,\n",
      "         -4.8511e-02, -7.6359e-02,  1.3123e-01,  1.5838e-02,  1.2111e-01,\n",
      "          9.2165e-02,  2.3904e-02, -4.4562e-02, -5.0332e-02,  6.3842e-03],\n",
      "        [ 4.4515e-02,  3.6032e-03,  1.3511e-01, -6.3314e-02, -1.4100e-01,\n",
      "          1.0600e-01, -1.1931e-01,  1.2068e-01,  1.3227e-01,  7.4928e-02,\n",
      "         -6.5064e-02,  6.1054e-02,  1.2756e-02, -7.9842e-02, -1.2689e-01,\n",
      "         -1.0940e-01, -2.0650e-02,  5.0403e-02, -8.6626e-02, -7.5462e-02,\n",
      "         -6.5353e-02, -1.1938e-01,  1.1779e-01, -2.9931e-02, -1.1095e-01,\n",
      "         -8.0951e-02, -1.0081e-01,  5.3903e-02, -4.6048e-02,  1.3731e-02,\n",
      "          7.0075e-02, -4.4929e-02, -1.1889e-01, -1.3662e-02,  2.3097e-02,\n",
      "          1.1071e-01,  1.3960e-01, -2.2729e-02, -1.3784e-02, -1.3447e-01,\n",
      "          7.1119e-02,  6.0484e-02, -7.8543e-02,  5.3383e-02, -1.3492e-01,\n",
      "         -1.0852e-01, -2.2273e-03,  4.1131e-02, -1.0403e-02,  1.2820e-01],\n",
      "        [ 9.8418e-03,  2.1921e-02,  1.1857e-01, -1.4109e-01, -5.0822e-02,\n",
      "         -4.2585e-02, -2.1071e-02,  2.4969e-03,  9.5503e-02,  9.2140e-02,\n",
      "         -1.2492e-01, -1.2655e-01, -4.0285e-02,  1.0848e-01, -1.1958e-01,\n",
      "          8.3719e-02, -6.4038e-02,  6.9139e-02,  1.0576e-01, -1.8774e-02,\n",
      "         -5.0610e-02, -3.4333e-02,  2.6334e-02,  3.7723e-02,  9.7411e-02,\n",
      "          2.6005e-02, -9.0125e-02, -1.0783e-01, -5.0443e-02,  5.0076e-02,\n",
      "          1.4012e-02, -5.0692e-04, -1.0697e-01,  1.3712e-01,  3.5586e-02,\n",
      "         -2.6018e-02,  6.0560e-03, -1.0086e-01,  7.2787e-02, -7.5471e-03,\n",
      "          1.3890e-01, -3.0622e-03, -2.7671e-02,  1.3713e-01, -1.0754e-01,\n",
      "         -1.3651e-01,  1.0342e-01, -1.1277e-01, -1.0127e-01, -6.4430e-02],\n",
      "        [-4.5950e-03, -1.2288e-01, -1.3492e-01,  4.4224e-02,  1.3002e-01,\n",
      "         -8.7485e-02,  2.3870e-02,  1.7421e-02,  5.0408e-02, -3.3340e-02,\n",
      "         -3.5528e-02,  8.5984e-02, -7.8442e-02,  6.7609e-02, -5.6368e-02,\n",
      "         -7.0786e-02, -3.5401e-02,  1.2901e-01, -9.5331e-02, -3.9246e-02,\n",
      "         -5.4445e-02, -5.5110e-02,  6.8780e-02, -7.3383e-02, -5.1678e-02,\n",
      "          1.3828e-01,  9.3964e-02,  9.7656e-02, -2.2894e-02,  6.5024e-02,\n",
      "         -6.6763e-02, -7.8018e-02, -1.0994e-01, -8.5350e-02,  1.1030e-01,\n",
      "          2.7566e-02,  7.9900e-02, -2.6210e-02,  1.0536e-01, -7.1971e-04,\n",
      "         -1.2860e-01, -1.2429e-01,  1.3952e-01,  9.2056e-02, -1.5981e-02,\n",
      "         -5.5654e-02, -3.0508e-02,  2.9978e-02, -5.0522e-02,  5.5259e-03],\n",
      "        [ 2.7745e-02,  1.2467e-01,  5.9692e-02,  9.1377e-02, -1.2928e-01,\n",
      "          3.7108e-02, -7.1762e-02,  1.0571e-01,  3.6022e-02,  2.7068e-02,\n",
      "         -2.1663e-03,  1.0932e-01, -7.5724e-02,  3.5517e-02, -6.3227e-02,\n",
      "         -7.5660e-02, -1.0735e-01, -5.3265e-02,  1.3413e-01, -3.4273e-03,\n",
      "          1.0872e-01, -6.3162e-02, -8.3105e-02, -1.0678e-01, -3.6923e-03,\n",
      "         -2.1262e-02,  1.4015e-01, -1.0445e-01, -1.0523e-01, -9.5776e-02,\n",
      "          6.8287e-02,  2.1285e-02, -9.4906e-02,  6.3702e-02, -9.1282e-02,\n",
      "         -4.0247e-02, -5.1795e-02,  9.6276e-02, -4.8484e-03,  1.2376e-01,\n",
      "          3.2300e-02, -1.2112e-01,  9.5203e-02,  1.3496e-01, -1.0697e-01,\n",
      "          5.1106e-02,  4.9419e-02, -8.6677e-02, -9.0288e-02, -1.3958e-01],\n",
      "        [-8.6207e-02, -9.0626e-02, -4.8799e-02,  4.0411e-02, -1.3861e-01,\n",
      "          1.2912e-01,  8.0439e-02,  5.0029e-02,  1.4646e-02,  3.7514e-03,\n",
      "          1.1661e-01,  2.2981e-02,  1.1549e-01,  9.8208e-02,  2.4764e-02,\n",
      "         -3.6641e-02,  8.6320e-03, -1.0529e-01, -1.2130e-01,  1.5391e-02,\n",
      "         -1.1736e-01,  1.7851e-02,  2.5738e-02, -1.0341e-01,  1.4632e-02,\n",
      "         -7.4029e-02, -3.6686e-02, -1.0104e-01,  9.8046e-02,  1.2530e-02,\n",
      "          1.3446e-01, -1.3358e-02,  9.3551e-02, -8.0289e-02, -4.7860e-02,\n",
      "         -1.4014e-01,  4.7371e-02,  2.8880e-02,  1.3016e-01, -5.9019e-02,\n",
      "         -7.6073e-02, -2.7025e-02, -5.9956e-03,  7.2762e-02, -1.4086e-01,\n",
      "         -2.1732e-02, -2.4532e-02,  5.4662e-02, -9.4961e-02, -6.8221e-02],\n",
      "        [ 2.5012e-02,  1.1943e-01, -4.7263e-02, -3.3603e-02,  1.0521e-01,\n",
      "         -3.8180e-02,  7.4077e-02,  1.1726e-01,  1.1839e-01, -1.3209e-01,\n",
      "          5.9598e-02,  1.1096e-01,  4.6874e-02, -1.2972e-02,  7.0661e-02,\n",
      "         -1.3747e-01, -7.4233e-02,  8.6874e-02,  1.2013e-01,  1.4040e-04,\n",
      "          1.0228e-01,  5.6284e-02, -2.6253e-02, -1.2177e-01,  5.7906e-02,\n",
      "          5.1644e-02,  1.3177e-01,  1.1495e-01,  3.0610e-02, -2.5155e-02,\n",
      "         -3.6734e-02,  2.4812e-02, -8.8803e-02, -6.2525e-02,  5.4103e-02,\n",
      "         -3.1335e-02,  1.0865e-01,  6.1210e-02, -9.9984e-02, -6.1133e-02,\n",
      "          4.3063e-02, -7.0218e-02,  1.6138e-02, -1.2388e-01,  1.1948e-01,\n",
      "         -1.0913e-01,  2.2364e-02, -1.2700e-01,  6.4558e-03, -7.7047e-02],\n",
      "        [ 3.2533e-02,  8.1851e-02,  8.8797e-02,  1.0579e-01,  1.4220e-02,\n",
      "         -1.3782e-02,  9.2456e-02, -3.9254e-02, -9.2557e-02, -1.3072e-01,\n",
      "          8.2872e-02,  3.3785e-02, -1.1991e-01, -8.0472e-02,  8.0218e-02,\n",
      "          9.8948e-02,  6.4751e-02, -1.3049e-01,  8.9275e-02, -1.6533e-02,\n",
      "          1.3573e-01, -1.3365e-01, -7.8270e-02, -1.5122e-02,  2.1563e-02,\n",
      "         -1.1117e-01, -8.8367e-02, -4.8612e-02, -1.2196e-01,  1.3081e-01,\n",
      "         -2.0578e-02, -1.3736e-02,  1.4132e-01,  2.2689e-02, -1.2158e-01,\n",
      "          5.1260e-02, -1.2915e-01, -5.7137e-02,  8.2816e-03,  5.7260e-02,\n",
      "         -1.3315e-01, -1.2558e-01, -1.2804e-01,  8.7443e-02, -6.5688e-02,\n",
      "         -2.1304e-03,  3.1090e-02,  1.3004e-01,  1.2993e-01,  3.5112e-03]])), ('fc2.bias', tensor([ 0.0519, -0.0940,  0.0453, -0.0107, -0.0045,  0.0994,  0.0744,  0.0616,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -0.1068, -0.0470]))])\n",
      "\n",
      "optimizer\n",
      "{'state': {0: {'step': tensor(938.), 'exp_avg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}, 1: {'step': tensor(938.), 'exp_avg': tensor([ 2.0878e-04,  5.6052e-45, -3.6323e-04, -5.6135e-04,  2.5027e-03,\n",
      "        -1.3808e-03, -5.9705e-04, -1.0966e-03,  4.2360e-05,  2.0591e-03,\n",
      "         9.9269e-13,  3.4056e-04, -4.8536e-04, -5.5165e-04,  3.3153e-04,\n",
      "        -2.0003e-03, -2.9905e-05,  2.0644e-03,  5.5347e-05, -1.6789e-03,\n",
      "         6.9984e-04,  1.1405e-03, -1.3198e-03, -1.6525e-03, -3.3089e-03,\n",
      "        -2.0898e-03,  1.9055e-03, -8.4014e-04, -1.0875e-03,  2.5287e-03,\n",
      "        -1.1743e-03,  1.4638e-04, -1.0925e-03,  7.7645e-04, -2.6566e-03,\n",
      "        -2.3918e-04,  5.6052e-45, -4.4346e-04, -2.2504e-04,  6.9556e-04,\n",
      "         2.0826e-03, -1.5917e-03, -1.8906e-03, -1.2708e-03, -9.7671e-04,\n",
      "        -2.5394e-04, -1.6654e-03,  2.7574e-04, -8.1705e-04, -1.4537e-03]), 'exp_avg_sq': tensor([3.1838e-05, 7.4042e-08, 2.7406e-05, 1.9332e-05, 2.2801e-05, 3.3915e-05,\n",
      "        4.6090e-05, 3.7984e-05, 4.0888e-05, 2.1527e-05, 2.8773e-07, 4.3723e-05,\n",
      "        4.1886e-05, 2.5305e-05, 1.9132e-05, 2.5314e-05, 3.9149e-05, 3.3106e-05,\n",
      "        2.8723e-05, 4.5326e-05, 3.1154e-05, 4.7450e-05, 2.7543e-05, 1.8082e-05,\n",
      "        4.1830e-05, 4.4972e-05, 3.0482e-05, 2.2246e-05, 3.4241e-05, 2.8631e-05,\n",
      "        3.7179e-05, 3.3698e-05, 2.9987e-05, 3.8521e-05, 4.6162e-05, 2.5471e-05,\n",
      "        1.2060e-09, 2.2819e-05, 3.3992e-05, 4.3169e-05, 3.2054e-05, 2.5701e-05,\n",
      "        2.5562e-05, 2.8227e-05, 3.7900e-05, 4.8414e-05, 3.2136e-05, 4.5139e-05,\n",
      "        2.8924e-05, 4.3054e-05])}, 2: {'step': tensor(938.), 'exp_avg': tensor([[-3.1527e-04,  5.6052e-45, -7.4880e-04,  7.4114e-04,  3.4522e-03,\n",
      "         -8.7047e-03, -2.4503e-03, -5.5592e-03,  1.9185e-03,  2.1276e-03,\n",
      "          9.6996e-15,  1.4859e-03, -1.7216e-03,  1.7776e-03, -2.4093e-03,\n",
      "         -1.0509e-02, -3.1961e-03,  1.4466e-03, -3.6137e-03, -2.7288e-03,\n",
      "          8.6458e-04, -3.3017e-03, -1.2322e-02,  1.4681e-03,  1.7598e-04,\n",
      "          1.4865e-03, -6.1077e-03, -6.8550e-03, -7.2633e-03, -1.3472e-03,\n",
      "         -8.9102e-03, -2.4475e-03, -2.1663e-03, -4.1418e-05, -6.8506e-03,\n",
      "          7.0108e-04,  5.6052e-45, -5.9940e-03, -3.2774e-04, -4.5424e-03,\n",
      "         -9.1199e-03, -1.3280e-02, -1.9171e-03, -2.7633e-03, -9.6294e-03,\n",
      "         -2.2942e-03, -4.7647e-03, -1.4308e-03, -4.9242e-03,  2.4131e-03],\n",
      "        [ 1.0658e-03,  5.6052e-45,  1.1528e-03, -4.0761e-05, -1.4881e-03,\n",
      "          2.8849e-03,  6.2845e-06,  2.8408e-03, -1.7289e-04, -5.2703e-05,\n",
      "          1.7469e-15, -1.1027e-04,  9.5713e-04, -2.9489e-03,  1.0790e-03,\n",
      "          2.8901e-03,  6.2657e-04, -2.6326e-03,  5.6045e-04, -1.3086e-04,\n",
      "         -2.9608e-04,  4.8452e-04,  4.3466e-03, -1.6148e-03, -1.8344e-03,\n",
      "         -2.5819e-03,  1.3265e-03,  1.7912e-03,  1.9940e-03, -2.4315e-03,\n",
      "          3.0083e-03, -2.0954e-04,  6.2851e-04, -3.0188e-04,  2.9275e-03,\n",
      "         -1.1303e-03,  5.6052e-45, -1.3628e-03, -5.6184e-04, -9.2711e-04,\n",
      "          1.9408e-03,  4.2904e-03,  9.4353e-04,  1.2624e-03,  2.8774e-03,\n",
      "         -1.0722e-03,  1.4319e-03, -1.1645e-03,  1.3213e-03, -4.3158e-04],\n",
      "        [-9.7921e-03, -5.6052e-45, -6.8595e-03, -6.6380e-03, -6.7986e-03,\n",
      "          1.6969e-03, -1.7641e-03,  2.5361e-03, -6.9221e-03, -6.9705e-03,\n",
      "          5.5289e-14, -1.6526e-03, -1.1835e-02,  1.4024e-04,  3.0144e-03,\n",
      "         -2.4719e-03,  5.4006e-03, -1.6586e-03, -7.3131e-03, -2.7146e-03,\n",
      "          2.7507e-03,  1.7023e-03, -9.3893e-03,  1.9496e-03, -6.3850e-03,\n",
      "          2.6540e-03, -6.5718e-03, -3.3393e-03,  2.7201e-03,  1.3675e-04,\n",
      "          6.7638e-03,  3.7344e-03, -2.1631e-03,  1.0486e-04, -3.9600e-03,\n",
      "          8.8856e-03,  5.6052e-45,  3.3624e-05, -4.0117e-03,  5.0999e-03,\n",
      "         -3.8777e-03, -3.3302e-04, -1.3438e-03,  3.7082e-03, -3.8961e-03,\n",
      "          1.7761e-03,  7.0496e-03, -4.6852e-03,  1.2710e-03, -6.6046e-03],\n",
      "        [-5.2648e-03,  5.6052e-45, -2.6511e-03, -8.3698e-03, -2.2573e-03,\n",
      "         -3.0758e-03, -1.5339e-03, -6.6676e-03,  2.5425e-04, -3.4717e-03,\n",
      "          9.4145e-15, -6.9024e-03, -8.5750e-04, -3.6232e-03,  2.9333e-03,\n",
      "          4.5059e-03, -1.3104e-02,  2.2503e-03,  3.6417e-03, -7.6006e-03,\n",
      "          1.0398e-03,  3.6443e-03, -6.0366e-03,  5.1849e-05, -5.8956e-03,\n",
      "         -3.7171e-04,  4.9801e-04, -5.5099e-04, -3.4360e-03, -7.5278e-03,\n",
      "         -4.0542e-03, -7.6857e-03, -1.0520e-02,  1.2901e-03,  3.3917e-03,\n",
      "         -4.6479e-03,  5.6052e-45,  3.6158e-03, -4.5758e-03, -1.2030e-02,\n",
      "          7.9848e-04,  3.0382e-03, -1.2478e-02, -1.3134e-02,  5.8308e-04,\n",
      "          4.0604e-03, -8.2350e-03, -5.9984e-04, -3.5192e-03, -2.0368e-03],\n",
      "        [-1.4364e-02,  5.6052e-45, -1.4443e-02, -1.1862e-02, -2.4237e-02,\n",
      "         -2.8844e-03, -6.6894e-03, -2.8120e-03, -1.5798e-02, -1.9403e-02,\n",
      "         -5.6410e-13, -1.5722e-02, -1.4699e-02, -1.4610e-02, -7.8860e-03,\n",
      "         -2.0999e-03, -9.6090e-03, -4.4476e-03, -9.9422e-03, -2.2610e-04,\n",
      "          2.4262e-03, -2.2382e-03, -9.2472e-03,  2.5743e-03, -4.8854e-04,\n",
      "         -1.1463e-02, -1.0964e-02, -5.8367e-03,  3.5984e-04, -8.8937e-03,\n",
      "         -1.1156e-03, -9.0896e-03, -7.2460e-03, -2.8633e-03, -1.5978e-03,\n",
      "         -2.4810e-03, -5.6052e-45, -9.3561e-04, -1.5264e-02, -1.1670e-02,\n",
      "         -9.8994e-03, -2.7705e-03, -7.3987e-03,  5.8106e-04, -3.3148e-03,\n",
      "         -3.8606e-03, -2.1154e-03, -4.4150e-04, -1.6424e-03, -1.1321e-02],\n",
      "        [-2.4854e-03,  5.6052e-45, -8.7616e-03, -7.2865e-03, -5.3364e-03,\n",
      "         -4.2596e-03, -3.6585e-03, -3.1924e-03, -9.2153e-03, -4.6513e-03,\n",
      "          1.8352e-14, -5.4022e-03, -2.7375e-04, -5.2343e-03, -7.9553e-03,\n",
      "         -7.4406e-03, -3.0602e-03, -8.4811e-04, -4.3479e-03,  1.6474e-03,\n",
      "         -1.1365e-02, -5.7486e-03, -5.4271e-03, -1.7713e-02,  1.6186e-03,\n",
      "         -7.3621e-03, -1.8628e-03,  1.3277e-04,  1.2268e-03, -1.3152e-04,\n",
      "         -1.4548e-03,  3.3571e-04,  4.3226e-04, -2.4503e-03, -6.8731e-03,\n",
      "         -5.8826e-03,  5.6052e-45, -2.9115e-03, -5.3152e-03,  1.0461e-03,\n",
      "         -1.7401e-03, -4.3977e-03, -5.4956e-03,  1.1011e-03, -3.3333e-03,\n",
      "         -8.8739e-03, -4.3124e-03, -2.0243e-03, -1.8463e-03, -6.7159e-03],\n",
      "        [ 1.3320e-02, -5.6052e-45,  1.1288e-02,  1.4695e-02,  1.5781e-02,\n",
      "          1.2153e-02,  1.5170e-02,  1.2535e-02,  1.4741e-02,  1.4328e-02,\n",
      "          1.3897e-13,  9.0944e-03,  1.4810e-02,  4.0201e-03,  6.3848e-03,\n",
      "          1.0160e-02,  1.3316e-02,  3.5962e-03,  5.9405e-03,  5.3018e-03,\n",
      "          1.5392e-03,  9.1414e-03,  1.9484e-02,  3.0556e-03,  4.0507e-03,\n",
      "          7.0626e-03,  1.4201e-02,  7.7493e-03,  3.0287e-03,  1.1640e-02,\n",
      "          5.3637e-03,  4.6579e-03,  4.5884e-03,  4.5009e-03,  9.6600e-03,\n",
      "          4.9819e-03,  5.6052e-45,  2.3890e-03,  9.6482e-03,  4.3704e-03,\n",
      "          1.2182e-02,  1.2179e-02,  8.3547e-03,  3.9054e-03,  9.1643e-03,\n",
      "          6.3320e-03,  9.2455e-03,  7.4658e-03,  8.9465e-03,  1.3066e-02],\n",
      "        [ 2.1897e-03,  5.6052e-45,  4.4194e-03,  4.5697e-03,  6.2404e-03,\n",
      "          2.2923e-03,  3.6387e-03,  2.2104e-03,  1.2053e-03,  2.7570e-03,\n",
      "          3.7405e-14,  5.3383e-03,  8.2952e-04,  3.2811e-03,  2.2958e-03,\n",
      "          2.2757e-03,  6.5586e-03,  1.5276e-03, -7.1023e-04,  1.6156e-03,\n",
      "          1.0196e-03,  2.5439e-03,  3.3349e-03,  3.9586e-03,  2.0135e-03,\n",
      "          3.9980e-03,  7.3306e-04,  1.6097e-03,  4.4271e-03,  4.2761e-03,\n",
      "          2.5514e-03,  5.4518e-03,  4.7046e-03,  1.0120e-03,  2.0092e-04,\n",
      "          5.8323e-03,  5.6052e-45,  1.6319e-03,  4.7684e-03,  7.8000e-03,\n",
      "          1.6221e-03,  8.7137e-04,  5.7912e-03,  4.4693e-03, -6.8611e-04,\n",
      "         -5.0310e-04,  2.8946e-03,  1.2235e-03,  1.5905e-04,  2.3950e-03],\n",
      "        [-7.1100e-03, -5.6052e-45, -6.2458e-03, -7.1354e-03, -1.0572e-02,\n",
      "         -6.9343e-03, -1.0526e-02, -9.0101e-03, -4.5752e-03, -7.8659e-03,\n",
      "          4.7878e-14, -7.3162e-03,  1.3807e-04, -6.7942e-03, -2.6166e-03,\n",
      "         -1.1789e-03, -1.7066e-02, -7.9278e-03,  8.4449e-04, -3.7928e-03,\n",
      "          1.7200e-03, -1.0579e-02, -4.1572e-03,  4.0719e-03,  7.6259e-04,\n",
      "         -7.4153e-03, -3.6708e-03, -5.5377e-03, -4.6189e-03, -1.2416e-02,\n",
      "         -7.7541e-03, -1.2135e-02, -6.4251e-03, -6.2812e-03, -1.6808e-03,\n",
      "         -1.4938e-02,  5.6052e-45,  2.1148e-03, -1.0855e-02, -1.3664e-02,\n",
      "         -3.6155e-03, -1.9068e-03, -7.9781e-03, -8.7872e-03, -1.9236e-03,\n",
      "          3.0577e-03, -1.0944e-02, -2.7633e-03, -3.9270e-03, -8.4317e-03],\n",
      "        [ 2.2756e-02, -5.6052e-45,  2.2850e-02,  2.1326e-02,  2.5217e-02,\n",
      "          6.8321e-03,  7.8066e-03,  7.1190e-03,  1.8564e-02,  2.3202e-02,\n",
      "          2.4534e-13,  2.1187e-02,  1.2653e-02,  2.3991e-02,  5.1600e-03,\n",
      "          3.8687e-03,  2.0133e-02,  8.6939e-03,  1.4940e-02,  8.6289e-03,\n",
      "          3.0087e-04,  4.3510e-03,  1.9414e-02,  2.1978e-03,  5.9823e-03,\n",
      "          1.3993e-02,  1.2418e-02,  1.0837e-02,  1.5617e-03,  1.6695e-02,\n",
      "          5.6017e-03,  1.7388e-02,  1.8167e-02,  5.0302e-03,  4.7821e-03,\n",
      "          8.6791e-03,  5.6052e-45,  1.4188e-03,  2.6495e-02,  2.4517e-02,\n",
      "          1.1709e-02,  2.3093e-03,  2.1522e-02,  9.6567e-03,  1.0158e-02,\n",
      "          1.3778e-03,  9.7501e-03,  4.4201e-03,  4.1612e-03,  1.7668e-02]]), 'exp_avg_sq': tensor([[4.7559e-04, 5.2779e-09, 5.1980e-04, 1.6859e-04, 5.0121e-04, 5.8849e-04,\n",
      "         5.0987e-04, 3.4705e-04, 2.9918e-04, 4.4637e-04, 1.4914e-08, 2.4273e-04,\n",
      "         5.0803e-04, 1.4636e-04, 1.9329e-04, 1.1496e-03, 3.1438e-04, 1.2250e-04,\n",
      "         7.7471e-04, 1.1332e-04, 5.0805e-05, 5.3536e-04, 1.7030e-03, 7.1870e-05,\n",
      "         4.6669e-05, 7.0459e-05, 9.5986e-04, 7.2426e-04, 3.3615e-04, 2.5778e-04,\n",
      "         5.6477e-04, 1.6820e-04, 1.9386e-04, 4.1031e-04, 6.9002e-04, 1.6479e-04,\n",
      "         9.3581e-12, 4.1507e-04, 2.3590e-04, 2.7793e-04, 1.1061e-03, 1.2917e-03,\n",
      "         2.7040e-04, 1.4691e-04, 1.0949e-03, 2.1462e-04, 3.5485e-04, 1.1216e-04,\n",
      "         3.0836e-04, 1.2343e-04],\n",
      "        [1.4194e-04, 6.8882e-10, 1.5281e-04, 2.3709e-04, 2.7115e-04, 2.2369e-04,\n",
      "         3.3614e-04, 2.4321e-04, 8.8653e-05, 1.2234e-04, 8.1310e-09, 1.3892e-04,\n",
      "         9.0413e-05, 2.9741e-04, 7.0665e-06, 1.1003e-04, 9.9611e-04, 3.5717e-04,\n",
      "         8.4122e-05, 3.7042e-04, 1.5936e-05, 2.7992e-04, 2.5972e-04, 2.2223e-04,\n",
      "         4.7971e-05, 1.3955e-04, 1.4697e-04, 1.0835e-04, 2.0121e-04, 7.3477e-04,\n",
      "         1.4414e-04, 3.3194e-04, 1.8918e-04, 1.0071e-04, 6.2497e-05, 5.0110e-04,\n",
      "         1.4173e-11, 7.7482e-05, 3.9099e-04, 5.3329e-04, 1.5287e-04, 1.3404e-04,\n",
      "         4.2338e-04, 4.5140e-04, 1.1874e-04, 5.0642e-05, 5.3108e-04, 3.6241e-04,\n",
      "         2.4168e-04, 3.0941e-04],\n",
      "        [1.2716e-03, 4.3934e-09, 5.8576e-04, 7.0058e-04, 8.5882e-04, 1.3616e-03,\n",
      "         9.8233e-04, 1.2111e-03, 4.4253e-04, 7.0021e-04, 8.4858e-10, 4.3574e-04,\n",
      "         1.3614e-03, 3.4645e-04, 1.6791e-04, 7.2971e-04, 1.9054e-03, 4.6350e-04,\n",
      "         6.6004e-04, 9.6545e-04, 3.9435e-05, 5.8403e-04, 2.7885e-03, 6.4969e-05,\n",
      "         3.1763e-04, 1.6110e-04, 1.3793e-03, 1.1663e-03, 7.1000e-04, 1.3030e-03,\n",
      "         1.3979e-03, 7.5843e-04, 1.0849e-03, 3.1633e-04, 5.1523e-04, 3.8784e-04,\n",
      "         1.4982e-11, 2.1563e-04, 7.2496e-04, 1.1148e-03, 1.4485e-03, 1.3777e-03,\n",
      "         1.1098e-03, 1.1361e-03, 1.1203e-03, 2.2010e-04, 1.5944e-03, 8.6413e-04,\n",
      "         1.1469e-03, 5.9817e-04],\n",
      "        [1.0283e-03, 7.4231e-09, 1.6029e-03, 8.0812e-04, 7.0948e-04, 1.5430e-03,\n",
      "         6.2245e-04, 1.0527e-03, 3.5948e-04, 5.9598e-04, 1.0967e-08, 1.0704e-03,\n",
      "         5.6440e-04, 7.9770e-04, 1.9258e-04, 1.7045e-03, 2.2195e-03, 4.2529e-04,\n",
      "         9.7270e-04, 7.2847e-04, 2.8117e-04, 6.2168e-04, 3.0137e-03, 8.9763e-05,\n",
      "         2.1371e-04, 2.6103e-04, 9.9995e-04, 1.4230e-03, 1.1537e-03, 1.0610e-03,\n",
      "         2.0503e-03, 1.8921e-03, 1.4895e-03, 3.9408e-04, 9.5302e-04, 9.1661e-04,\n",
      "         1.5422e-11, 7.4054e-04, 1.7948e-03, 2.9748e-03, 1.4535e-03, 1.8986e-03,\n",
      "         2.0554e-03, 1.7268e-03, 1.6219e-03, 2.2099e-04, 1.6481e-03, 3.3812e-04,\n",
      "         7.8599e-04, 4.4769e-04],\n",
      "        [1.3898e-03, 8.5722e-10, 1.6295e-03, 8.8508e-04, 2.4539e-03, 2.0170e-04,\n",
      "         4.2443e-04, 1.6461e-04, 1.2428e-03, 1.5110e-03, 3.5093e-08, 1.2570e-03,\n",
      "         1.4638e-03, 1.3731e-03, 2.7192e-04, 3.4734e-04, 4.2164e-04, 3.0680e-04,\n",
      "         1.2105e-03, 2.3027e-04, 1.8244e-05, 2.4272e-04, 1.6308e-03, 1.0605e-04,\n",
      "         3.3406e-04, 6.5794e-04, 9.4052e-04, 6.0721e-04, 1.0058e-04, 4.3409e-04,\n",
      "         1.1751e-04, 5.1204e-04, 6.8312e-04, 3.5668e-04, 3.6229e-04, 2.6521e-04,\n",
      "         9.0816e-10, 9.1540e-05, 1.2239e-03, 8.3693e-04, 9.2176e-04, 4.0888e-04,\n",
      "         6.8525e-04, 2.0982e-04, 5.3014e-04, 7.0250e-05, 1.2547e-04, 2.1595e-04,\n",
      "         1.4227e-04, 6.2925e-04],\n",
      "        [7.0827e-04, 2.6255e-09, 1.7789e-03, 9.7280e-04, 7.5375e-04, 1.6030e-03,\n",
      "         7.2767e-04, 8.4300e-04, 9.1031e-04, 6.3578e-04, 1.7145e-08, 1.1575e-03,\n",
      "         4.3464e-04, 7.2571e-04, 4.6499e-04, 2.3795e-03, 1.3151e-03, 2.2097e-04,\n",
      "         1.0180e-03, 3.8174e-04, 5.4741e-04, 8.1493e-04, 3.2511e-03, 3.3382e-04,\n",
      "         6.6132e-05, 6.0929e-04, 8.8500e-04, 9.9686e-04, 5.9920e-04, 7.1995e-04,\n",
      "         1.4207e-03, 8.4530e-04, 5.1331e-04, 5.5989e-04, 1.4588e-03, 9.9094e-04,\n",
      "         1.3472e-11, 1.1187e-03, 1.2386e-03, 1.4451e-03, 1.0136e-03, 2.0454e-03,\n",
      "         1.8072e-03, 8.0575e-04, 1.9715e-03, 5.5725e-04, 1.4525e-03, 2.1429e-04,\n",
      "         4.8511e-04, 6.0299e-04],\n",
      "        [3.6636e-04, 2.8199e-08, 4.0725e-04, 6.3063e-04, 9.2571e-04, 7.2070e-04,\n",
      "         7.5657e-04, 5.5037e-04, 7.6796e-04, 7.0223e-04, 1.2129e-09, 4.7956e-04,\n",
      "         8.4135e-04, 1.1906e-04, 2.6680e-04, 7.9329e-04, 3.9391e-04, 1.3214e-04,\n",
      "         2.8383e-04, 4.1704e-04, 1.6874e-04, 3.3600e-04, 1.7470e-03, 8.2677e-05,\n",
      "         7.0855e-05, 2.5778e-04, 9.2338e-04, 2.2656e-04, 1.4084e-04, 7.3327e-04,\n",
      "         1.4633e-04, 8.8528e-05, 1.1985e-04, 1.8772e-04, 4.1657e-04, 2.7140e-04,\n",
      "         8.7672e-12, 2.7457e-04, 2.0414e-04, 1.6675e-04, 7.2662e-04, 9.4492e-04,\n",
      "         3.6676e-04, 1.7858e-04, 5.2803e-04, 3.2348e-04, 4.2937e-04, 4.6185e-04,\n",
      "         5.4580e-04, 2.7596e-04],\n",
      "        [9.4471e-04, 2.7920e-09, 1.4462e-03, 2.5478e-04, 1.2710e-03, 1.9982e-04,\n",
      "         1.3546e-04, 1.3887e-04, 2.7893e-04, 7.3126e-04, 5.1088e-09, 5.1689e-04,\n",
      "         8.5537e-04, 1.3430e-03, 1.0131e-04, 2.7969e-04, 6.5913e-04, 9.0741e-04,\n",
      "         1.4868e-03, 1.6471e-04, 1.3899e-05, 4.4423e-04, 5.9986e-04, 5.3106e-05,\n",
      "         6.6322e-05, 1.5046e-04, 7.7508e-04, 1.0928e-03, 2.6343e-04, 4.6084e-04,\n",
      "         6.6750e-04, 1.3452e-03, 1.1837e-03, 3.7862e-04, 2.4617e-04, 2.9978e-04,\n",
      "         9.6664e-12, 1.2940e-04, 1.5886e-03, 1.6841e-03, 1.2898e-03, 3.3137e-04,\n",
      "         3.6540e-04, 2.6147e-04, 5.1650e-04, 6.1132e-05, 2.3588e-04, 1.6447e-04,\n",
      "         1.4817e-04, 3.4340e-04],\n",
      "        [1.7463e-03, 5.9750e-09, 1.5320e-03, 1.1518e-03, 1.2018e-03, 1.4415e-03,\n",
      "         1.2263e-03, 1.1618e-03, 8.3527e-04, 1.0562e-03, 3.7639e-09, 1.2131e-03,\n",
      "         7.4460e-04, 1.0924e-03, 3.9326e-04, 1.2232e-03, 2.9065e-03, 5.0185e-04,\n",
      "         9.1714e-04, 5.3808e-04, 1.4212e-04, 1.0071e-03, 3.2213e-03, 2.0471e-04,\n",
      "         1.3277e-04, 7.1147e-04, 1.1873e-03, 1.4237e-03, 7.2972e-04, 1.2146e-03,\n",
      "         1.4702e-03, 1.0868e-03, 1.1219e-03, 8.3618e-04, 1.0010e-03, 1.2853e-03,\n",
      "         1.0334e-11, 3.4799e-04, 1.4435e-03, 1.9887e-03, 1.2314e-03, 1.1295e-03,\n",
      "         2.4684e-03, 1.2683e-03, 1.7419e-03, 1.9174e-04, 2.1450e-03, 3.0979e-04,\n",
      "         4.2550e-04, 1.0460e-03],\n",
      "        [2.1798e-03, 4.7469e-09, 2.8671e-03, 7.6782e-04, 2.8167e-03, 4.0018e-04,\n",
      "         3.4870e-04, 1.9180e-04, 1.0595e-03, 2.0565e-03, 5.2822e-09, 1.6488e-03,\n",
      "         1.3754e-03, 2.5362e-03, 3.4237e-04, 5.3107e-04, 9.4126e-04, 8.0871e-04,\n",
      "         2.4508e-03, 1.3357e-04, 4.6377e-05, 5.2686e-04, 1.8423e-03, 7.7998e-05,\n",
      "         1.6557e-04, 6.7348e-04, 1.5573e-03, 1.5002e-03, 2.6721e-04, 6.0992e-04,\n",
      "         6.8666e-04, 1.5251e-03, 1.5091e-03, 7.6995e-04, 4.2833e-04, 5.3006e-04,\n",
      "         6.5487e-12, 1.9821e-04, 2.4257e-03, 2.4537e-03, 1.9212e-03, 5.0273e-04,\n",
      "         1.2382e-03, 4.1212e-04, 1.1813e-03, 1.0070e-04, 3.0741e-04, 9.0571e-05,\n",
      "         8.7997e-05, 7.2150e-04]])}, 3: {'step': tensor(938.), 'exp_avg': tensor([-0.0011,  0.0002, -0.0014, -0.0020, -0.0027, -0.0038,  0.0047,  0.0021,\n",
      "        -0.0002,  0.0040]), 'exp_avg_sq': tensor([9.8958e-05, 1.1633e-04, 1.8548e-04, 2.1906e-04, 1.8244e-04, 2.3735e-04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1.2201e-04, 1.6426e-04, 2.6061e-04, 2.5889e-04])}}, 'param_groups': [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': False, 'params': [0, 1, 2, 3]}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in checkpoint.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the checkpoint has been saved as a file in the given path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the checkpoint:\n",
    "\n",
    "def load_checkpoint(checkpoint):\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    \n",
    "#can even save accuracy and such in the checkpoint dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"))\n",
    "#loads the model and optimizer values\n",
    "#torch.load(filename) -> given as checkpoint valued for function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
